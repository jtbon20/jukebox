{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_House.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC7uOJ7x4LiQ"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8Brdfh6mzEz"
      },
      "source": [
        "!apt install ffmpeg\n",
        "!pip install spleeter\n",
        "!pip install youtube-dl\n",
        "from IPython.display import Audio\n",
        "import librosa\n",
        "import librosa.display\n",
        "import youtube_dl\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "\n",
        "folder = '/content/gdrive/MyDrive/DeepHouse/'\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive/', force_remount=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afbcUSken16L"
      },
      "source": [
        "# Build Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGvyBZ_UDdkv"
      },
      "source": [
        "def splitSong(songPath,outPath , splitSize=300):\n",
        "  !ffmpeg -i $songPath -f segment -segment_time 300 -c copy $outPath%03d.m4a\n",
        "\n",
        "def splitSongs(path, out, remove=True):\n",
        "  # iterate over songs, splitting into chunks\n",
        "  for song in [f for f in os.listdir(path) if f.endswith('.m4a')]:\n",
        "    split = song.split('.')[0]\n",
        "    print('Splitting ' + str(split))\n",
        "    splitSong(songPath=path+song,outPath=path+split+'_')\n",
        "    !mkdir $out/$split/ # make the directory to ultimately save to\n",
        "    \n",
        "    # if remove, delete base song\n",
        "    if remove:\n",
        "      os.remove(path+song)\n",
        "\n",
        "def downloadPlaylist(path, url):\n",
        "    dlPath = \"\\'\"+path+\"%(playlist_index)s.%(ext)s\\'\"\n",
        "    !youtube-dl -f 'bestaudio[ext=m4a]' -o $dlPath $url\n",
        "\n",
        "def createTmpDir(path):\n",
        "  ! rm -rf $path; mkdir $path\n",
        "\n",
        "def saveBars(path, name, out):\n",
        "  # load the song into librosa\n",
        "  y, sr = librosa.load(path, sr=None)\n",
        "  y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
        "  tempo, beats = librosa.beat.beat_track(y=y_percussive, sr=sr)\n",
        "\n",
        "  # create our time chunks, make all 16 beat bars, and only keep every 4\n",
        "  bars_frame = [(beats[beat], beats[beat+15]) for beat in list(range(len(beats)-15))][0::4] \n",
        "  bars=librosa.frames_to_time(bars_frame)\n",
        "\n",
        "  # save our cuts\n",
        "  for idx, bar in enumerate(bars):\n",
        "    barOut = out+name.split('_')[0]+'/'+ name.split('_')[1]+'_' +str(idx) + '_' + str(round(tempo,0)).split('.')[0] + '.m4a'\n",
        "    length =  bar[1] - bar[0] # end - beginning\n",
        "    start = bar[0]\n",
        "    ! ffmpeg -ss $start -i $path -t $length -c copy $barOut\n",
        "\n",
        " # get a set of all 'parsed' files to skip them\n",
        "def getExists(path):\n",
        "  preproc = set() # do this once since listdir takes time\n",
        "  for dir in os.listdir(path):\n",
        "    for f in os.listdir(os.path.join(path, dir)):\n",
        "      # change to file format in 'tmp file'\n",
        "      preproc.add(dir+'_'+f.split('_')[0]) \n",
        "\n",
        "  return preproc\n",
        "\n",
        "def processSongs(path, out, bpmCut=False): # path is location of src; out is dest\n",
        "  songs = [f for f in os.listdir(path) if f.endswith('.m4a')]\n",
        "  preproc = getExists(out) # set of all to skip, to allow for restarts \n",
        "\n",
        "  # for all songs\n",
        "  for idx, song in enumerate(songs):\n",
        "    name = song.split('.')[0]\n",
        "\n",
        "    # process if new, else skip\n",
        "    if name not in preproc: \n",
        "      print('Processing ' +str(round(100*idx/len(songs),2))+' | ' + str(song))\n",
        "      # split the song delete the audio\n",
        "      !spleeter separate -o $path $path$song -c m4a \n",
        "\n",
        "      # overwrite the song with the split vocals\n",
        "      output = path+name+'/accompaniment.m4a'\n",
        "      if bpmCut:\n",
        "        saveBars(path=output, name=name, out=out)\n",
        "      else:\n",
        "        cp $output $out/$song\n",
        "\n",
        "      # and delete the vocals + newly created folder\n",
        "      newFolder = path+song.split('.')[0]\n",
        "      ! rm -rf $newFolder\n",
        "    else:\n",
        "      print('Skipping ' +str(round(100 * idx/len(songs),2))+' | ' + str(song))\n",
        "\n",
        "def createData(url, folder):\n",
        "  # make a temp folder to save the songs in on disk\n",
        "  tmpPath = '/content/musicDLtmp/'\n",
        "  createTmpDir(tmpPath)\n",
        "  \n",
        "  # download the youtube playlist, and split the songs\n",
        "  downloadPlaylist(tmpPath, url)\n",
        "  splitSongs(tmpPath, folder) # 5 min chunks (max parse time for spleeter=10mins)\n",
        "\n",
        "  # for each song, remove vocals, extract bpm and save the cut bars \n",
        "  processSongs(path=tmpPath, out=folder)\n",
        "\n",
        "url = '' # youtube playlist here\n",
        "dlFolder = '/content/gdrive/MyDrive/DeepHouse/1-Input/'\n",
        "createData(url=url, folder=dlFolder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew7CecFX4QiE"
      },
      "source": [
        "# Train Prior on Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNdrDKJg4Q0w"
      },
      "source": [
        "Inspired by @Zaags Training Prior 1.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A39KiAWN5ZCM"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/gdrive/MyDrive/DeepHouse/deephouse_prior/logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kff06I3P4jfP"
      },
      "source": [
        "lemodel = 'deephouse' # your model name\n",
        "leeventlog = False\n",
        "\n",
        "audioDir = folder + '1-Input/DL/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgLeYIcq4uZT"
      },
      "source": [
        "!pip install git+https://github.com/openai/jukebox.git\n",
        "!git clone https://github.com/openai/jukebox.git\n",
        "!pip install av\n",
        "!pip install tensorboardX \n",
        "import os\n",
        "\n",
        "lemodelpath = folder + lemodel + '_prior/checkpoint_latest.pth.tar'\n",
        "leaudio_files_dir = dlFolder\n",
        "lepriorname = lemodel + '_prior'\n",
        "\n",
        "print(lemodelpath,leaudio_files_dir,lepriorname,os.path.isfile(lemodelpath))\n",
        "\n",
        "############### To Change to Google Drive\n",
        "\n",
        "fin = open(\"/usr/local/lib/python3.7/dist-packages/jukebox/utils/logger.py\", \"rt\")\n",
        "data = fin.read()\n",
        "data = data.replace('logdir = f\"{hps.local_logdir}/{hps.name}\"', 'logdir = f\"/content/gdrive/MyDrive/DeepHouse/{hps.name}\"')\n",
        "fin.close()\n",
        "fin = open(\"/usr/local/lib/python3.7/dist-packages/jukebox/utils/logger.py\", \"wt\")\n",
        "fin.write(data)\n",
        "fin.close()\n",
        "\n",
        "############### To Sample with Google Drive\n",
        "\n",
        "fin = open(\"/usr/local/lib/python3.7/dist-packages/jukebox/hparams.py\", \"rt\")\n",
        "data = fin.read()\n",
        "fin.close()\n",
        "\n",
        "data += lemodel + \"\"\"_prior = Hyperparams()   \n",
        "\"\"\" + lemodel + \"\"\"_prior.update(small_prior)\n",
        "\"\"\" + lemodel + \"\"\"_prior.restore_prior='\"\"\" + lemodelpath + \"\"\"'\n",
        "\"\"\" + lemodel + \"\"\"_prior.n_ctx=8192\n",
        "\"\"\" + lemodel + \"\"\"_prior.l_bins=2048\n",
        "\"\"\" + lemodel + \"\"\"_prior.level=2\n",
        "\"\"\" + lemodel + \"\"\"_prior.labels=False\n",
        "HPARAMS_REGISTRY['\"\"\" + lemodel + \"\"\"_prior'] = \"\"\" + lemodel + \"\"\"_prior\n",
        "\"\"\"\n",
        "\n",
        "data = data.replace('min_duration=60.0','min_duration=24.0')\n",
        "data = data.replace('max_duration=600.0','max_duration=666.0')\n",
        "\n",
        "fin = open(\"/usr/local/lib/python3.7/dist-packages/jukebox/hparams.py\", \"wt\")\n",
        "fin.write(data)\n",
        "fin.close()\n",
        "\n",
        "\n",
        "####################### step print\n",
        "\n",
        "fin = open(\"/content/jukebox/jukebox/train.py\", \"rt\")\n",
        "data = fin.read()\n",
        "fin.close()\n",
        "\n",
        "data = data.replace('log_inputs(orig_model, logger, x_in, y, x_out, hps)','log_inputs(orig_model, logger, x_in, y, x_out, hps);print(colored(\"steps:\" + str(logger.iters),\"green\"))')\n",
        "data = \"\"\"from termcolor import colored\n",
        "\n",
        "\"\"\" + data\n",
        "\n",
        "if leeventlog == False:\n",
        "  data = data.replace('logger.flush()','#logger.flush()')\n",
        "  \n",
        "fin = open(\"/content/jukebox/jukebox/train.py\", \"wt\")\n",
        "fin.write(data)\n",
        "fin.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSJOPKeF5RpY"
      },
      "source": [
        "lehps = ('vqvae,small_prior,all_fp16,cpu_ema','vqvae,'+lepriorname+',all_fp16,cpu_ema')[os.path.isfile(lemodelpath)]\n",
        "print((\"new training model\",lepriorname + \" model found\")[os.path.isfile(lemodelpath)])\n",
        "\n",
        "!python jukebox/jukebox/train.py \\\n",
        "--prior --test --train --aug_shift --aug_blend \\\n",
        "--hps=$lehps \\\n",
        "--save_iters=500 \\\n",
        "--levels=3 \\\n",
        "--level=2 \\\n",
        "--labels=False \\\n",
        "--name=$lepriorname \\\n",
        "--sample_length=1048576     \\\n",
        "--bs=7 \\\n",
        "--audio_files_dir=$leaudio_files_dir  \\\n",
        "--n_ctx=8192 \\\n",
        "--weight_decay=0.01 \n",
        "\n",
        "#--restore_prior=\"path/to/checkpoint\" --lr_use_linear_decay --lr_start_linear_decay={already_trained_steps} --lr_decay={decay_steps_as_needed}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPd9z5Xm4VMg"
      },
      "source": [
        "# Create Sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX5ly0Z94XmN"
      },
      "source": [
        "# Stopped mid level = 2? use continue\n",
        "# Stopped mid level = 1 or 0? use upsample\n",
        "\n",
        "lemode = 'ancestral'     # 'ancestral','primed','continue','cutcontinue','upsample'\n",
        "\n",
        "lecount = 15\n",
        "lesample_length_in_seconds = 90\n",
        "lesampling_temperature = .98\n",
        "lehop = [.75,1,.125]                 #default [.5,.5,.125], optimized [1,1,0.0625]\n",
        "\n",
        "lepath = '/content/gdrive/MyDrive/DeepHouse/2-Output/'\n",
        "\n",
        "leprompt_length_in_seconds=0  \n",
        "# leaudio_file = '/content/gdrive/MyDrive/DeepHouse/1-Input/DL/014_060.m4a'                    \n",
        "\n",
        "lecut = 70               # used only on cutcontinue\n",
        "transpose = [0,1,2]      # used only on cutcontinue [0,1,2] = default, ex [1,1,1] all samples are copied from item 1\n",
        "\n",
        "leexportlyrics = False\n",
        "leprogress = True\n",
        "leautorename = True\n",
        "\n",
        "leartist = \"unknown\"\n",
        "legenre = \"house\"\n",
        "lelyrics = \"\"\n",
        "\n",
        "lecustommodellyrics = False\n",
        "\n",
        "lechunk_size = 16 \n",
        "lemax_batch_size = (17,3)['5b' in lemodel]\n",
        "lelower_batch_size = lecount\n",
        "lelower_level_chunk_size = lechunk_size * 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM4WRQDP4iUF"
      },
      "source": [
        "if lemode=='ancestral':\n",
        "  leprompt_length_in_seconds=None  \n",
        "  leaudio_file = None\n",
        "###############################################################################\n",
        "###############################################################################\n",
        "\n",
        "codes_file=None\n",
        "\n",
        "!pip install git+https://github.com/openai/jukebox.git\n",
        "\n",
        "##$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#### autosave start\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "filex = \"/usr/local/lib/python3.7/dist-packages/jukebox/sample.py\"\n",
        "fin = open(filex, \"rt\")\n",
        "data = fin.read()\n",
        "fin.close()\n",
        "\n",
        "newtext = '''import fire\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "from termcolor import colored\n",
        "from datetime import datetime\n",
        "\n",
        "newtosample = True'''\n",
        "data = data.replace('import fire',newtext)\n",
        "\n",
        "newtext = '''starts = get_starts(total_length, prior.n_ctx, hop_length)\n",
        "        counterr = 0\n",
        "        x = None\n",
        "        for start in starts:'''\n",
        "data = data.replace('for start in get_starts(total_length, prior.n_ctx, hop_length):',newtext)\n",
        "\n",
        "newtext = '''global newtosample\n",
        "    newtosample = (new_tokens > 0)\n",
        "    if new_tokens <= 0:'''\n",
        "data = data.replace('if new_tokens <= 0:',newtext)\n",
        "\n",
        "newtext = '''counterr += 1\n",
        "            datea = datetime.now()\t\t\n",
        "            zs = sample_single_window(zs, labels, sampling_kwargs, level, prior, start, hps)\t\t\t\n",
        "            if newtosample and counterr < len(starts):\n",
        "                del x; x = None; prior.cpu(); empty_cache()\n",
        "                x = prior.decode(zs[level:], start_level=level, bs_chunks=zs[level].shape[0])\n",
        "                logdir = f\"{hps.name}/level_{level}\"\n",
        "                if not os.path.exists(logdir):\n",
        "                    os.makedirs(logdir)\n",
        "                t.save(dict(zs=zs, labels=labels, sampling_kwargs=sampling_kwargs, x=x), f\"{logdir}/data.pth.tar\")\n",
        "                save_wav(logdir, x, hps.sr)\n",
        "                del x; prior.cuda(); empty_cache(); x = None\n",
        "            dateb = datetime.now()\n",
        "            timex = ((dateb-datea).total_seconds()/60.0)*(len(starts)-counterr)\n",
        "            print(f\"Step \" + colored(counterr,'blue') + \"/\" + colored( len(starts),'red') + \" ~ New to Sample: \" + str(newtosample) + \" ~ estimated remaining minutes: \" + (colored('???','yellow'), colored(timex,'magenta'))[counterr > 1 and newtosample])'''\n",
        "data = data.replace('zs = sample_single_window(zs, labels, sampling_kwargs, level, prior, start, hps)',newtext)\n",
        "\n",
        "\n",
        "newtext = \"\"\"lepath=hps.name\n",
        "        if level==2:\n",
        "          for filex in glob(os.path.join(lepath + '/level_2','item_*.wav')):\n",
        "            os.rename(filex,filex.replace('item_',lepath.split('/')[-1] + '-'))\n",
        "        if level==1:\n",
        "          for filex in glob(os.path.join(lepath + '/level_1','item_*.wav')):\n",
        "            os.rename(filex,filex.replace('item_',lepath.split('/')[-1] + '-L1-'))\n",
        "        if level==0:\n",
        "          for filex in glob(os.path.join(lepath + '/level_0','item_*.wav')):\n",
        "            os.rename(filex,filex.replace('item_',lepath.split('/')[-1] + '-L0-'))\n",
        "        save_html(\"\"\"\n",
        "if leautorename:\n",
        "  data = data.replace('save_html(',newtext)\n",
        "\n",
        "if leexportlyrics == False:\n",
        "  data = data.replace('if alignments is None','#if alignments is None')\n",
        "  data = data.replace('alignments = get_alignment','#alignments = get_alignment')\n",
        "  data = data.replace('save_html(','#save_html(')\n",
        "\n",
        "if leprogress == False:\n",
        "  data = data.replace('print(f\"Step \" +','#print(f\"Step \" +')\n",
        "  \n",
        "fin = open(filex, \"wt\")\n",
        "fin.write(data)\n",
        "fin.close()\n",
        "##$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#### autosave end\n",
        "\n",
        "###CUSTOM MODEL############ To Sample with Google Drive\n",
        "if not '1b' in lemodel and not '5b' in lemodel:\n",
        "  lemodelpath = '/content/gdrive/MyDrive/DeepDeepHouse/' + lemodel + '_prior/checkpoint_latest.pth.tar'\n",
        "  fin = open(\"/usr/local/lib/python3.7/dist-packages/jukebox/hparams.py\", \"rt\")\n",
        "  data = fin.read();  fin.close()\n",
        "  \n",
        "  if lecustommodellyrics:\n",
        "    data += lemodel + \"\"\"_prior = Hyperparams()   \n",
        "\"\"\" + lemodel + \"\"\"_prior.update(small_single_enc_dec_prior)\n",
        "\"\"\" + lemodel + \"\"\"_prior.restore_prior='\"\"\" + lemodelpath + \"\"\"'\n",
        "\"\"\" + lemodel + \"\"\"_prior.n_ctx=8192\n",
        "\"\"\" + lemodel + \"\"\"_prior.alignment_layer=47\n",
        "\"\"\" + lemodel + \"\"\"_prioralignment_head=0\n",
        "\"\"\" + lemodel + \"\"\"_prior.l_bins=2048\n",
        "\"\"\" + lemodel + \"\"\"_prior.level=2\n",
        "HPARAMS_REGISTRY['\"\"\" + lemodel + \"\"\"_prior'] = \"\"\" + lemodel + \"\"\"_prior\n",
        "\"\"\"\n",
        "  else:\n",
        "    data += lemodel + \"\"\"_prior = Hyperparams()   \n",
        "\"\"\" + lemodel + \"\"\"_prior.update(small_prior)\n",
        "\"\"\" + lemodel + \"\"\"_prior.restore_prior='\"\"\" + lemodelpath + \"\"\"'\n",
        "\"\"\" + lemodel + \"\"\"_prior.n_ctx=8192\n",
        "\"\"\" + lemodel + \"\"\"_prior.l_bins=2048\n",
        "\"\"\" + lemodel + \"\"\"_prior.level=2\n",
        "\"\"\" + lemodel + \"\"\"_prior.labels=False\n",
        "HPARAMS_REGISTRY['\"\"\" + lemodel + \"\"\"_prior'] = \"\"\" + lemodel + \"\"\"_prior\n",
        "\"\"\"\n",
        "    \n",
        "\n",
        "  data = data.replace('y_bins=(10,100)','y_bins=(604, 7898)')\n",
        "  data = data.replace('min_duration=60.0','min_duration=24.0')\n",
        "  data = data.replace('max_duration=600.0','max_duration=666.0')\n",
        "\n",
        "  fin = open(\"/usr/local/lib/python3.7/dist-packages/jukebox/hparams.py\", \"wt\")\n",
        "  fin.write(data);  fin.close()\n",
        "\n",
        "  fin = open(\"/usr/local/lib/python3.7/dist-packages/jukebox/make_models.py\", \"rt\")\n",
        "  data = fin.read(); fin.close()  \n",
        "\n",
        "  data = data.replace(\"#'your_model': \",\"'\" +lemodel + \"_model': \")\n",
        "  data = data.replace('(\"you_vqvae_here\", \"your_upsampler_here\", ..., \"you_top_level_prior_here\")','(\"vqvae\",  \"upsampler_level_0\", \"upsampler_level_1\", \"' + lemodel + '_prior\"),')\n",
        "\n",
        "  fin = open(\"/usr/local/lib/python3.7/dist-packages/jukebox/make_models.py\", \"wt\")\n",
        "  fin.write(data); fin.close()  \n",
        "\n",
        "  lemodel = lemodel + \"_model\"\n",
        "###CUSTOM MODEL END############\n",
        "\n",
        "import jukebox\n",
        "import torch as t\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from IPython.display import Audio\n",
        "from jukebox.make_models import make_vqvae, make_prior, MODELS, make_model\n",
        "from jukebox.hparams import Hyperparams, setup_hparams\n",
        "from jukebox.sample import sample_single_window, _sample, \\\n",
        "                           sample_partial_window, upsample, \\\n",
        "                           load_prompts\n",
        "from jukebox.utils.dist_utils import setup_dist_from_mpi\n",
        "from jukebox.utils.torch_utils import empty_cache\n",
        "rank, local_rank, device = setup_dist_from_mpi()\n",
        "\n",
        "print(datetime.now().strftime(\"%H:%M:%S\"))\n",
        "\n",
        "model = lemodel\n",
        "hps = Hyperparams()\n",
        "hps.sr = 44100\n",
        "hps.n_samples = lecount \n",
        "hps.name = lepath\n",
        "\n",
        "chunk_size = lechunk_size\n",
        "max_batch_size = lemax_batch_size\n",
        "\n",
        "hps.levels = 3\n",
        "hps.hop_fraction = lehop\n",
        "\n",
        "vqvae, *priors = MODELS[model]\n",
        "vqvae = make_vqvae(setup_hparams(vqvae, dict(sample_length = 1048576)), device)\n",
        "top_prior = make_prior(setup_hparams(priors[-1], dict()), vqvae, device)\n",
        "\n",
        "# Prime song creation using an arbitrary audio sample.\n",
        "mode = lemode\n",
        "codes_file=None\n",
        "audio_file = leaudio_file\n",
        "prompt_length_in_seconds=leprompt_length_in_seconds\n",
        "\n",
        "\n",
        "if os.path.exists(hps.name):\n",
        "  # Identify the lowest level generated and continue from there.\n",
        "  for level in [0, 1, 2]:\n",
        "    data = f\"{hps.name}/level_{level}/data.pth.tar\"\n",
        "    if os.path.isfile(data):\n",
        "      mode = mode if 'continue' in mode else 'upsample'\n",
        "      codes_file = data\n",
        "      print(mode + 'ing from level ' + str(level))\n",
        "      break\n",
        "print('mode is now '+mode)\n",
        "\n",
        "sample_hps = Hyperparams(dict(mode=mode, codes_file=codes_file, audio_file=audio_file, prompt_length_in_seconds=prompt_length_in_seconds))\n",
        "\n",
        "sample_length_in_seconds = lesample_length_in_seconds \n",
        "hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "assert hps.sample_length >= top_prior.n_ctx*top_prior.raw_to_tokens, f'Please choose a larger sampling rate'\n",
        "\n",
        "metas = [dict(artist = leartist,\n",
        "            genre = legenre,\n",
        "            total_length = hps.sample_length,\n",
        "            offset = 0,\n",
        "            lyrics = lelyrics,\n",
        "            ),\n",
        "          ] * hps.n_samples\n",
        "labels = [None, None, top_prior.labeller.get_batch_labels(metas, 'cuda')]\n",
        "\n",
        "\n",
        "#----------------------------------------------------------2\n",
        "\n",
        "\n",
        "sampling_temperature = lesampling_temperature\n",
        "lower_batch_size = lelower_batch_size\n",
        "max_batch_size = lemax_batch_size\n",
        "lower_level_chunk_size = lelower_level_chunk_size\n",
        "chunk_size = lechunk_size \n",
        "sampling_kwargs = [dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                        chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                         chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=sampling_temperature, fp16=True, \n",
        "                         max_batch_size=max_batch_size, chunk_size=chunk_size)]\n",
        "\n",
        "print(sample_hps.mode)\n",
        "print(sample_hps.prompt_length_in_seconds)\n",
        "print(hps.sr)\n",
        "print(top_prior.raw_to_tokens)\n",
        "print('aaaaaaaaaaaaaaaaaaaaaaaaaaaa 4.55')\n",
        "\n",
        "if sample_hps.mode == 'ancestral':\n",
        "  zs = [t.zeros(hps.n_samples,0,dtype=t.long, device='cuda') for _ in range(len(priors))]\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "elif sample_hps.mode == 'upsample':\n",
        "  assert sample_hps.codes_file is not None\n",
        "  # Load codes.\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zs = [z.cuda() for z in data['zs']]\n",
        "  assert zs[-1].shape[0] == hps.n_samples, f\"Expected bs = {hps.n_samples}, got {zs[-1].shape[0]}\"\n",
        "  del data\n",
        "  print('Falling through to the upsample step later in the notebook.')\n",
        "elif sample_hps.mode == 'primed':\n",
        "  assert sample_hps.audio_file is not None\n",
        "  audio_files = sample_hps.audio_file.split(',')\n",
        "  duration = (int(sample_hps.prompt_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "  \n",
        "  x = load_prompts(audio_files, duration, hps)\n",
        "  zs = top_prior.encode(x, start_level=0, end_level=len(priors), bs_chunks=x.shape[0])\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "elif sample_hps.mode == 'continue':\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zs = [z.cuda() for z in data['zs']]\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "elif sample_hps.mode == 'cutcontinue':\n",
        "  print('-------CUT INIT--------')\n",
        "  lecutlen = (int(lecut*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "  print(lecutlen)\n",
        "  data = t.load(codes_file, map_location='cpu')\n",
        "  zabaca = [z.cuda() for z in data['zs']]\n",
        "  print(zabaca)\n",
        "  assert zabaca[-1].shape[0] == hps.n_samples, f\"Expected bs = {hps.n_samples}, got {zs[-1].shape[0]}\"\n",
        "  priorsz = [top_prior] * 3\n",
        "  top_raw_to_tokens = priorsz[-1].raw_to_tokens\n",
        "  assert lecutlen % top_raw_to_tokens == 0, f\"Cut-off duration {lecutlen} not an exact multiple of top_raw_to_tokens\"\n",
        "  assert lecutlen//top_raw_to_tokens <= zabaca[-1].shape[1], f\"Cut-off tokens {lecutlen//priorsz[-1].raw_to_tokens} longer than tokens {zs[-1].shape[1]} in saved codes\"\n",
        "  zabaca = [z[:,:lecutlen//prior.raw_to_tokens] for z, prior in zip(zabaca, priorsz)]\n",
        "  hps.sample_length = lecutlen\n",
        "  print(zabaca)\n",
        "  zs = _sample(zabaca, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "  del data\n",
        "  print('-------CUT OK--------')\n",
        "  hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zibica = [z.cuda() for z in data['zs']]\n",
        "  zubu = zibica[:]\n",
        "  if transpose != [0,1,2]:\n",
        "    zubu[2][0] = zibica[:][2][transpose[0]];zubu[2][1] = zibica[:][2][transpose[1]];zubu[2][2] = zibica[:][2][transpose[2]]\n",
        "    zubu[1][0] = zibica[:][1][transpose[0]];zubu[1][1] = zibica[:][1][transpose[1]];zubu[1][2] = zibica[:][1][transpose[2]]\n",
        "    zubu[0][0] = zibica[:][0][transpose[0]];zubu[0][1] = zibica[:][0][transpose[1]];zubu[0][2] = zibica[:][0][transpose[2]]\n",
        "  zubu = _sample(zubu, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "  print('-------CONTINUE AFTER CUT OK--------')\n",
        "  zs = zubu\n",
        "else:\n",
        "  raise ValueError(f'Unknown sample mode {sample_hps.mode}.')\n",
        "\n",
        "\n",
        "\n",
        "print(datetime.now().strftime(\"%H:%M:%S\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAh2j_0Y6HVf"
      },
      "source": [
        "print(datetime.now().strftime(\"%H:%M:%S\"))\n",
        "del top_prior\n",
        "empty_cache()\n",
        "top_prior=None\n",
        "\n",
        "upsamplers = [make_prior(setup_hparams(prior, dict()), vqvae, 'cpu') for prior in priors[:-1]]\n",
        "labels[:2] = [prior.labeller.get_batch_labels(metas, 'cuda') for prior in upsamplers]\n",
        "\n",
        "zs = upsample(zs, labels, sampling_kwargs, [*upsamplers, top_prior], hps)\n",
        "print(datetime.now().strftime(\"%H:%M:%S\"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}